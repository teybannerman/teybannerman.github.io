---
layout: post
title:  "AI development framework, 2019"
date:   2025-05-27 12:00:00 +0000
categories: ai design
---

This is me 6 years ago. September 2019. Taking the stage, talking about AI in a shirt I can only describe as... an interesting choice ðŸ˜…

![Tey Bannerman on stage in 2019 talking about AI](/images/tey-bannerman-ai-talk-2019.jpeg)

It was 4 years before ChatGPT became a cultural phenomenon and generative AI transformed from technical curiosity to a strategic mandate. The calm before the AI storm.

I was explaining to an audience of designers, researchers and innovators why they need to be involved in AI initiatives from day one. The room was divided between fascination and skepticism. Many believed AI belonged only to the realm of data scientists.

At the time, a lot of my work was helping banks and retailers build and extract meaningful insight from large-scale AI models: automating processes, personalising experiences, predicting customer behaviour. The results were promising, but something was missing: integration with the workflows and expectations of real people. We were seeing technically impressive systems that people either couldn't understand or didn't trust.

Working with the brilliant Allison Rowe, Suzanne Mouton, and Ellen Sundh, we developed a framework that placed human context at the centre vs as an afterthought. It emphasised:

* Bringing researchers/designers into technical decisions: what data to use, which biases to avoid, which outcomes to optimise for
* Starting with human problems, not technical possibilities
* Creating feedback loops that evolve with user behaviour

It wasn't revolutionary. But it bridged an important gap: connecting the people who understand technology with those who understand humans. It challenged the prevailing approach of treating AI as a purely technical exercise. And when we adopted this we saw dramatically higher adoption rates and measurable business impact.

Fast forward to today, six years later.
AI is everywhere.
Budgets have exploded.

But I'm watching history repeat itself:
Technical teams building solutions without the input of those who understand human behaviour.
Capability without context.
Power without purpose.

The stage is bigger now, the stakes are higher, and thankfully, my shirts have improved. But the core insight remains: we need to put decisions about AI in the hands of those who will use it, not just those who build it.

**If you're a designer**, your expertise has never been more valuable. Don't just design interfaces for AI - shape how AI models are trained and built. How they function within human systems. Your understanding of context and meaning is a game-changer.

**If you're a data scientist/engineer**, your technical brilliance multiplies in impact when paired with human insight. Invite designers into your process early, and measure success by real-world impact.

**If you're an executive leading digital/innovation**, your most strategic move isn't accelerating AI adoption, but ensuring it happens at the intersection of technical possibility and human reality. Build teams that bridge these worlds from day one.

-


_This post was adapted from my original [LinkedIn post][li-link] published in May 2025._

[li-link]: https://www.linkedin.com/posts/teybannerman_this-is-me-6-years-ago-september-2019-taking-activity-7333035502196977665-FUdn?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAGPfuABFdT2X7kv4xKZw0YytrrL5oqGPWQ